# ğŸ§  AI Post Analyzer

A complete **multimodal post analysis system** combining **text and image** using artificial intelligence.  
It leverages ğŸ¤— [Hugging Face Transformers](https://huggingface.co/transformers) and computer vision to evaluate **sentiment**, **readability**, **target audience**, **image quality**, and **textâ€“image alignment (CLIP)**.

---

## ğŸ“ Project Structure

```
app/
â”œâ”€â”€ logs/                    
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ clip_analyser.py         # CLIP-based imageâ€“text similarity analysis
â”œâ”€â”€ image_analyzer.py        # Image analysis (dimensions, faces)
â”œâ”€â”€ text_analyzer.py         # Text analysis (sentiment, readability, keywords)
â”œâ”€â”€ final_results.py         # Combines all results and calculates final score
â”œâ”€â”€ logger.py                # Centralized logging system
â”œâ”€â”€ main.py                  # FastAPI app entry point
â”œâ”€â”€ requirements.txt         # Project dependencies
â”œâ”€â”€ show.json                # Example of input/output
â””â”€â”€ test_api.py              # Tests and API integration
```

---

## âš™ï¸ Features

### TextAnalyzer
Performs **linguistic and semantic analysis** using NLP models.

- Target audience classification (age and gender)
- Sentiment analysis (positive, neutral, negative)
- Keyword extraction based on relevance
- Readability metrics (Flesch Reading Ease)

**Models used:**
- facebook/bart-large-mnli â†’ zero-shot classification  
- finiteautomata/bertweet-base-sentiment-analysis â†’ sentiment  
- ml6team/keyphrase-extraction-kbir-inspec â†’ keyword extraction  

---

### ImageAnalyzer
Analyzes an image from a URL and provides:

- Dimensions and size (in pixels and KB)
- Face detection using OpenCV (`haarcascade_frontalface_default.xml`)

**Libraries:**  
cv2, numpy, urllib

---

### ClipAnalyzer
Applies the **CLIP model (Contrastive Languageâ€“Image Pretraining)** to measure semantic similarity between text and image.

It computes embeddings and similarity levels (High, Medium, Low) between the post caption and the visual content.

**Default model:** `openai/clip-vit-base-patch32`

---

### final_results.py
Consolidates outputs from all analyzers and computes a **final engagement score (0â€“100)**, based on weighted metrics:

| Factor | Weight |
|--------|---------|
| Imageâ€“caption alignment (CLIP) | 30% |
| Sentiment positivity | 15% |
| Hashtag relevance | 10% |
| Hashtag quantity | 15% |
| Caption readability | 10% |
| Face presence | 15% |
| Image size/quality | 5% |

Also generates:
- Confidence interval
- Final classification (Excellent, Good, Fair, Needs improvement)
- Actionable tips for optimization

---

### logger.py
Manages logs per module and automatically creates timestamped `.log` files inside `/app/logs/<subfolder>/YYYY-MM-DD.log`.

**Example log output:**
```
[INFO] Starting TextAnalyzer.analyser orchestrator.
[INFO] Running hashtag analysis...
[ERROR] Error during face detection analysis: ...
```

---

### main.py â€” FastAPI Server
Provides an API endpoint for full post analysis.

**Endpoint:**  
`POST /analyze-post`

**Request body:**
```json
{
  "text": ["Your caption with #hashtags"],
  "image_url": "https://example.com/image.jpg"
}
```

**Response example:**
```json
{
  "sequence": "Your caption with hashtags",
  "hashtags": ["#AI", "#Innovation"],
  "final_analyse": "Good",
  "final_score": 73.4,
  "confidence_interval": [68.1, 78.6],
  "tips": "Consider featuring a face in the image to increase engagement."
}
```

---

## ğŸš€ How to Run Locally

1. Clone this repository and open the folder.  
2. Create and activate a virtual environment:  
   ```bash
   python -m venv .venv && .venv\Scripts\activate
   ```  
3. Install dependencies:  
   ```bash
   pip install -r requirements.txt
   ```  
4. Run the API:  
   ```bash
   python -m uvicorn app.main:app --reload
   ```  
5. Open http://localhost:8000/docs to test.

---


